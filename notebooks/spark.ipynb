{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3110c89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "from pyspark.sql import SparkSession, Row, functions as F, types as T\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import StringType, DoubleType\n",
    "import math\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6596a551",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .appName(\"Covid_Hive_HDFS\") \\\n",
    "    .config(\"spark.sql.catalogImplementation\", \"hive\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", \"hdfs://hadoop-namenode:9000/user/hive/warehouse\") \\\n",
    "    .config(\"spark.local.dir\", \"/tmp/spark\") \\\n",
    "    .config(\"spark.sql.hive.metastore.version\", \"4.0.1\") \\\n",
    "    .config(\"spark.sql.hive.metastore.jars\", \"/opt/hive/lib/*\") \\\n",
    "    .config(\"spark.hadoop.hive.metastore.uris\", \"thrift://hive-metastore:9083\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3759cb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"hdfs://hadoop-namenode:9000/user/hadoop/metadata/metadata_cleaned.csv\"\n",
    "\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"patientid\", StringType(), True),\n",
    "    StructField(\"offset\", StringType(), True),\n",
    "    StructField(\"sex\", StringType(), True),\n",
    "    StructField(\"age\", StringType(), True),\n",
    "    StructField(\"finding\", StringType(), True),\n",
    "    StructField(\"view\", StringType(), True),\n",
    "    StructField(\"modality\", StringType(), True),\n",
    "    StructField(\"date\", StringType(), True),\n",
    "    StructField(\"location\", StringType(), True),\n",
    "    StructField(\"folder\", StringType(), True),\n",
    "    StructField(\"filename\", StringType(), True),\n",
    "    StructField(\"url\", StringType(), True),\n",
    "    StructField(\"license\", StringType(), True),\n",
    "    StructField(\"clinical_notes\", StringType(), True),\n",
    "    StructField(\"age_group\", StringType(), True),\n",
    "    StructField(\"has_covid\", StringType(), True)\n",
    "])\n",
    "\n",
    "df = spark.read \\\n",
    "    .option(\"header\", True) \\\n",
    "    .option(\"multiLine\", True) \\\n",
    "    .option(\"quote\", '\"') \\\n",
    "    .option(\"escape\", '\"') \\\n",
    "    .schema(schema) \\\n",
    "    .csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "17d295fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+---+----+---------+----+--------+----------------+--------------------+------+--------------------+--------------------+--------+--------------------+-----------+---------+\n",
      "|patientid|offset|sex| age|  finding|view|modality|            date|            location|folder|            filename|                 url| license|      clinical_notes|  age_group|has_covid|\n",
      "+---------+------+---+----+---------+----+--------+----------------+--------------------+------+--------------------+--------------------+--------+--------------------+-----------+---------+\n",
      "|        2|   0.0|  M|65.0| COVID-19|  PA|   X-ray|January 22, 2020|Cho Ray Hospital,...|images|auntminnie-a-2020...|https://www.nejm....|    None|On January 22, 20...|     Senior|     True|\n",
      "|        2|   3.0|  M|65.0| COVID-19|  PA|   X-ray|January 25, 2020|Cho Ray Hospital,...|images|auntminnie-b-2020...|https://www.nejm....|    None|On January 22, 20...|     Senior|     True|\n",
      "|        2|   5.0|  M|65.0| COVID-19|  PA|   X-ray|January 27, 2020|Cho Ray Hospital,...|images|auntminnie-c-2020...|https://www.nejm....|    None|On January 22, 20...|     Senior|     True|\n",
      "|        2|   6.0|  M|65.0| COVID-19|  PA|   X-ray|January 28, 2020|Cho Ray Hospital,...|images|auntminnie-d-2020...|https://www.nejm....|    None|On January 22, 20...|     Senior|     True|\n",
      "|        4|   0.0|  F|52.0| COVID-19|  PA|   X-ray|January 25, 2020|Changhua Christia...|images|nejmc2001573_f1a....|https://www.nejm....|    None|diffuse infiltrat...|Middle-aged|     True|\n",
      "|        4|   5.0|  F|52.0| COVID-19|  PA|   X-ray|January 30, 2020|Changhua Christia...|images|nejmc2001573_f1b....|https://www.nejm....|    None|progressive diffu...|Middle-aged|     True|\n",
      "|        5|  NULL|  F|75.0|Pneumonia|  PA|   X-ray|            2017|                NULL|images|      ARDSSevere.png|https://en.wikipe...|CC BY-SA|Severe ARDS. Pers...|     Senior|    False|\n",
      "|        6|   0.0|  M|22.0| COVID-19|  PA|   X-ray| January 6, 2020|Wuhan Jinyintan H...|images|   lancet-case2a.jpg|https://www.thela...|    None|Case 2: chest x-r...|Young Adult|     True|\n",
      "|        6|   4.0|  M|57.0| COVID-19|  PA|   X-ray|January 10, 2020|Wuhan Jinyintan H...|images|   lancet-case2b.jpg|https://www.thela...|    None|Case 2: chest x-r...|Middle-aged|     True|\n",
      "|        3|   4.0|  M|74.0|Pneumonia|  AP|   X-ray|            2004|Mount Sinai Hospi...|images|SARS-10.1148rg.24...|https://pubs.rsna...|    None|SARS in a 74-year...|     Senior|    False|\n",
      "|        3|   9.0|  M|74.0|Pneumonia|  AP|   X-ray|            2004|Mount Sinai Hospi...|images|SARS-10.1148rg.24...|https://pubs.rsna...|    None|SARS in a 74-year...|     Senior|    False|\n",
      "|        3|  10.0|  M|74.0|Pneumonia|  AP|   X-ray|            2004|Mount Sinai Hospi...|images|SARS-10.1148rg.24...|https://pubs.rsna...|    None|SARS in a 74-year...|     Senior|    False|\n",
      "|        7|   7.0|  F|29.0|Pneumonia|  PA|   X-ray|            2004|Mount Sinai Hospi...|images|SARS-10.1148rg.24...|https://pubs.rsna...|    None|SARS in a 29-year...|Young Adult|    False|\n",
      "|        7|  12.0|  F|29.0|Pneumonia|  PA|   X-ray|            2004|Mount Sinai Hospi...|images|SARS-10.1148rg.24...|https://pubs.rsna...|    None|SARS in a 29-year...|Young Adult|    False|\n",
      "|        8|   9.0|  F|42.0|Pneumonia|  PA|   X-ray|            2004|Mount Sinai Hospi...|images|SARS-10.1148rg.24...|https://pubs.rsna...|    None|SARS in a 42-year...|      Adult|    False|\n",
      "|        9|   5.0|  F|46.0|Pneumonia|  AP|   X-ray|            2004|Mount Sinai Hospi...|images|SARS-10.1148rg.24...|https://pubs.rsna...|    None|SARS in a 46-year...|      Adult|    False|\n",
      "|        9|  17.0|  F|46.0|Pneumonia|  AP|   X-ray|            2004|Mount Sinai Hospi...|images|SARS-10.1148rg.24...|https://pubs.rsna...|    None|SARS in a 46-year...|      Adult|    False|\n",
      "|       10|  19.0|  F|73.0|Pneumonia|  AP|   X-ray|            2004|Mount Sinai Hospi...|images|SARS-10.1148rg.24...|https://pubs.rsna...|    None|SARS in a 73-year...|     Senior|    False|\n",
      "|       10|  27.0|  F|73.0|Pneumonia|  AP|   X-ray|            2004|Mount Sinai Hospi...|images|SARS-10.1148rg.24...|https://pubs.rsna...|    None|SARS in a 73-year...|     Senior|    False|\n",
      "|       10|  35.0|  F|73.0|Pneumonia|  AP|   X-ray|            2004|Mount Sinai Hospi...|images|SARS-10.1148rg.24...|https://pubs.rsna...|    None|SARS in a 73-year...|     Senior|    False|\n",
      "+---------+------+---+----+---------+----+--------+----------------+--------------------+------+--------------------+--------------------+--------+--------------------+-----------+---------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132248dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Запись с партиционированием и бакетированием\n",
    "df.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .partitionBy(\"finding\", \"age_group\") \\\n",
    "    .bucketBy(8, \"sex\", \"view\") \\\n",
    "    .sortBy(\"age\") \\\n",
    "    .format(\"parquet\") \\\n",
    "    .saveAsTable(\"covid_metadata_partitioned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be859bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+----+------------------+\n",
      "|patientid| finding| age|avg_age_by_finding|\n",
      "+---------+--------+----+------------------+\n",
      "|       70|COVID-19|65.0| 55.07534246575342|\n",
      "|      142|COVID-19|65.0| 55.07534246575342|\n",
      "|      142|COVID-19|65.0| 55.07534246575342|\n",
      "|      142|COVID-19|65.0| 55.07534246575342|\n",
      "|      142|COVID-19|65.0| 55.07534246575342|\n",
      "|      143|COVID-19|65.0| 55.07534246575342|\n",
      "|      199|COVID-19|65.0| 55.07534246575342|\n",
      "|      351|COVID-19|65.0| 55.07534246575342|\n",
      "|      446|COVID-19|65.0| 55.07534246575342|\n",
      "|      446|COVID-19|65.0| 55.07534246575342|\n",
      "|      446|COVID-19|65.0| 55.07534246575342|\n",
      "|      446|COVID-19|65.0| 55.07534246575342|\n",
      "|      305|COVID-19|66.0| 55.07534246575342|\n",
      "|      305|COVID-19|66.0| 55.07534246575342|\n",
      "|      307|COVID-19|66.0| 55.07534246575342|\n",
      "|      151|COVID-19|67.0| 55.07534246575342|\n",
      "|      155|COVID-19|67.0| 55.07534246575342|\n",
      "|      320|COVID-19|67.0| 55.07534246575342|\n",
      "|      320|COVID-19|67.0| 55.07534246575342|\n",
      "|      165|COVID-19|68.0| 55.07534246575342|\n",
      "+---------+--------+----+------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# SQL запрос для анализа данных\n",
    "query1 = spark.sql(\"\"\"\n",
    "    SELECT patientid, finding, age,\n",
    "           AVG(age) OVER (PARTITION BY finding) as avg_age_by_finding\n",
    "    FROM covid_metadata_partitioned\n",
    "    WHERE age IS NOT NULL\n",
    "\"\"\")\n",
    "\n",
    "query1.show()\n",
    "\n",
    "query1.write.mode(\"overwrite\").parquet(\n",
    "    \"hdfs://hadoop-namenode:9000/user/hadoop/covid_dataset/processed/query1_top_patients.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2ef54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+---+----+--------+----+--------+----------------+--------------------+------+--------------------+--------------------+-------+--------------------+-----------+---------+-----------+\n",
      "|patientid|offset|sex| age| finding|view|modality|            date|            location|folder|            filename|                 url|license|      clinical_notes|  age_group|has_covid|age_group_2|\n",
      "+---------+------+---+----+--------+----+--------+----------------+--------------------+------+--------------------+--------------------+-------+--------------------+-----------+---------+-----------+\n",
      "|        2|   0.0|  M|65.0|COVID-19|  PA|   X-ray|January 22, 2020|Cho Ray Hospital,...|images|auntminnie-a-2020...|https://www.nejm....|   None|On January 22, 20...|     Senior|     True|     Senior|\n",
      "|        2|   3.0|  M|65.0|COVID-19|  PA|   X-ray|January 25, 2020|Cho Ray Hospital,...|images|auntminnie-b-2020...|https://www.nejm....|   None|On January 22, 20...|     Senior|     True|     Senior|\n",
      "|        2|   5.0|  M|65.0|COVID-19|  PA|   X-ray|January 27, 2020|Cho Ray Hospital,...|images|auntminnie-c-2020...|https://www.nejm....|   None|On January 22, 20...|     Senior|     True|     Senior|\n",
      "|        2|   6.0|  M|65.0|COVID-19|  PA|   X-ray|January 28, 2020|Cho Ray Hospital,...|images|auntminnie-d-2020...|https://www.nejm....|   None|On January 22, 20...|     Senior|     True|     Senior|\n",
      "|        4|   0.0|  F|52.0|COVID-19|  PA|   X-ray|January 25, 2020|Changhua Christia...|images|nejmc2001573_f1a....|https://www.nejm....|   None|diffuse infiltrat...|Middle-aged|     True|Middle-aged|\n",
      "+---------+------+---+----+--------+----+--------+----------------+--------------------+------+--------------------+--------------------+-------+--------------------+-----------+---------+-----------+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Определение UDF для группировки по возрасту\n",
    "df_with_udf = df\n",
    "\n",
    "def age_group(age):\n",
    "    try:\n",
    "        age = float(age)\n",
    "    except (TypeError, ValueError):\n",
    "        return 'Unknown'\n",
    "    if math.isnan(age):\n",
    "        return 'Unknown'\n",
    "    elif age < 1:\n",
    "        return 'Infant'\n",
    "    elif age < 5:\n",
    "        return 'Toddler'\n",
    "    elif age < 12:\n",
    "        return 'Child'\n",
    "    elif age < 18:\n",
    "        return 'Teen'\n",
    "    elif age < 35:\n",
    "        return 'Young Adult'\n",
    "    elif age < 50:\n",
    "        return 'Adult'\n",
    "    elif age < 65:\n",
    "        return 'Middle-aged'\n",
    "    elif age < 80:\n",
    "        return 'Senior'\n",
    "    else:\n",
    "        return 'Elderly'\n",
    "\n",
    "age_group_udf = udf(age_group, StringType())\n",
    "\n",
    "df_with_udf = df_with_udf.withColumn(\"age_group_2\", age_group_udf(df.age))\n",
    "\n",
    "df_with_udf.show(5)\n",
    "\n",
    "df_with_udf.write.mode(\"overwrite\").parquet(\n",
    "     \"hdfs://hadoop-namenode:9000/user/hadoop/covid_dataset/processed/with_udf.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "98a1d401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+----+--------------------+\n",
      "|patientid| finding|view|           view_desc|\n",
      "+---------+--------+----+--------------------+\n",
      "|       70|COVID-19|  AP|Anteroposterior view|\n",
      "|      142|COVID-19|  AP|Anteroposterior view|\n",
      "|      142|COVID-19|  AP|Anteroposterior view|\n",
      "|      142|COVID-19|  AP|Anteroposterior view|\n",
      "|      142|COVID-19|  AP|Anteroposterior view|\n",
      "+---------+--------+----+--------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# JOIN metadata + view_lookup\n",
    "views = [\n",
    "        Row(view=\"PA\", view_desc=\"Posteroanterior view\"),\n",
    "        Row(view=\"AP\", view_desc=\"Anteroposterior view\"),\n",
    "        Row(view=\"LATERAL\", view_desc=\"Lateral view\")\n",
    "]\n",
    "views_df = spark.createDataFrame(views)\n",
    "views_df.createOrReplaceTempView(\"view_lookup\")\n",
    "\n",
    "query2 = spark.sql(\n",
    "    \"\"\"\n",
    "        SELECT m.patientid, m.finding, m.view, v.view_desc\n",
    "        FROM covid_metadata_partitioned m\n",
    "        LEFT JOIN view_lookup v\n",
    "        ON m.view = v.view\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "query2.write.mode(\"overwrite\").parquet(\n",
    "     \"hdfs://hadoop-namenode:9000/user/hadoop/covid_dataset/processed/query2_view_lookup_join.parquet\"\n",
    ")\n",
    "\n",
    "query2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fa9d3ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-----------+-------------+\n",
      "|diagnosis|covid_count|total_count|covid_percent|\n",
      "+---------+-----------+-----------+-------------+\n",
      "| COVID-19|        584|        950|        61.47|\n",
      "+---------+-----------+-----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Подзапрос для расчёта процента COVID-19\n",
    "query3 = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        'COVID-19' as diagnosis,\n",
    "        covid_count,\n",
    "        total_count,\n",
    "        ROUND(covid_count / total_count * 100, 2) as covid_percent\n",
    "    FROM (\n",
    "        SELECT\n",
    "            SUM(CASE WHEN finding = 'COVID-19' THEN 1 ELSE 0 END) as covid_count,\n",
    "            COUNT(*) as total_count\n",
    "        FROM covid_metadata_partitioned\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "query3.show()\n",
    "\n",
    "query3.write.mode(\"overwrite\").parquet(\n",
    "     \"hdfs://hadoop-namenode:9000/user/hadoop/covid_dataset/processed/query3_covid_stats.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5f937df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/17 20:06:44 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+---+----------+\n",
      "|patientid| age|sex|prediction|\n",
      "+---------+----+---+----------+\n",
      "|        2|65.0|  M|         0|\n",
      "|        2|65.0|  M|         0|\n",
      "|        2|65.0|  M|         0|\n",
      "|        2|65.0|  M|         0|\n",
      "|        4|52.0|  F|         1|\n",
      "+---------+----+---+----------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# ML — кластеризация KMeans\n",
    "# ------------------------------------------------------------\n",
    "indexer = StringIndexer(inputCol=\"sex\", outputCol=\"sex_index\", handleInvalid=\"keep\")\n",
    "df_ml = indexer.fit(df).transform(df)\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"age\", \"sex_index\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "df_ml = df_ml.withColumn(\"age\", col(\"age\").cast(DoubleType()))\n",
    "df_ml = assembler.transform(df_ml).na.drop(subset=[\"features\"])\n",
    "\n",
    "# Кластеризация\n",
    "kmeans = KMeans(k=3, seed=1)\n",
    "model = kmeans.fit(df_ml)\n",
    "predictions = model.transform(df_ml)\n",
    "\n",
    "predictions.select(\"patientid\", \"age\", \"sex\", \"prediction\").show(5)\n",
    "\n",
    "predictions.write.mode(\"overwrite\").parquet(\n",
    "    \"hdfs://hadoop-namenode:9000/user/hadoop/covid_dataset/processed/kmeans_clusters.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de8840e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
